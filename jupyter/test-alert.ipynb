{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To deal with alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, please execute this cell.\n",
    "That will create test-alert to alertmanager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "url='http://127.0.0.1:9093/api/v1/alerts'\n",
    "headers={\"Content-Type\": \"application/json\"}\n",
    "data=[{\"labels\":{\"alertname\":\"execjson-test-alert\", \"service\": \"files\"}}]\n",
    "requests.post(url, data=json.dumps(data), headers=headers)\n",
    "data=[{\"labels\":{\"alertname\":\"test-alert\"}}]\n",
    "requests.post(url, data=json.dumps(data), headers=headers)\n",
    "data=[{\"labels\":{\"alertname\":\"jupyter-upload-test\"}}]\n",
    "requests.post(url, data=json.dumps(data), headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then  \n",
    "http://ip:9093 (alertmanager),  \n",
    "will see several alerts,  \n",
    "and webhook will be sent to  \n",
    "http://ip (execjson),  \n",
    "and  \n",
    "http://ip:5001 (open-pager-url).\n",
    "\n",
    "Check that execjson had done a job based on the alert, with execjson joblog feature.  \n",
    "When open-pager-url is accessed, you'll see two windows are opened.  \n",
    "One is for google, which contain some information for an alert :(, the other is for jupyter notebook, which contains all the information to deal that alert.\n",
    "\n",
    "\n",
    "After that, check kibana, to see json resulted from execjson.  \n",
    "http://ip:5601 (kibana)\n",
    "\n",
    "\n",
    "\n",
    "There are some other applications for some usecases.  \n",
    "http://ip:9090 (prometheus)  \n",
    "http://ip:5000 (applcon)  \n",
    "http://ip:9200 (elasticsearch)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To deal with Service Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with service request, you can firstly try to open\n",
    "http://ip (execjson)\n",
    "\n",
    "Your customer can define their request based on this web page, that will review their input instead of you :), except for some requests such as the one which technically possible, but you have to judge from finantial point of view :(\n",
    "\n",
    "After you think their SR is ok, you can import SR to execjson and push 'exec'.\n",
    "\n",
    "Then you can check the result from joblog link, dashboard, and kibana.\n",
    "\n",
    "Customer also could see joblog link, although their access to the jobs is restricted by apache authorization.\n",
    "\n",
    "\n",
    "\n",
    "For a demo purpose, you can execute test-exception job, and you could see execjson will do some task based on the job definition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To add a new node to CMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a new node to CMDB,\n",
    "you firstly should add IPAM to some db.\n",
    "\n",
    "At this time, it uses applconn to define this, but in the future, it might use full-feature DCIM, such as netbox instead.\n",
    "\n",
    "After that, you can discover some values with the help of ansible, and applconn will import all the values to kibana, and visualize the connectivity from several point of view, which include application, server,  network, storage, container, although that has to be customized heavily for your environment :(\n",
    "\n",
    "Based on the value discovered, applconn also define prometheus exporter targets.\n",
    "\n",
    "For this demo, some containers with sshd will be set up, which implement haproxy and apache, and with your defining ip, user, password, it will start discovery and monitoring by prometheus, optionally visualize them by d3.js and searched by kibana.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some job at the new node from execjson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applconn recognize some ip, you can kick some basic jobs at that node, which include scp files from and to that node and kick some command on that node.\n",
    "\n",
    "For this demo, you can do filetransfer job and execshell job on the new node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create self-healing job from execjson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since execjson's job is kicked by web-service, when prometheus found some alert, alertmanager can kick execjson to do recovery job.\n",
    "\n",
    "Since most of the recovery jobs could use similar command with SRs, execjson might define json-based job, to deal with that alert.\n",
    "\n",
    "For that purpose, you can create a job to deal with haproxy-restart and httpd-restart, and export them to some directory on execjson node, and kick them from alertmanager.\n",
    "\n",
    "Next cell contains some logic to do that task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wrap up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In old days, we set up all the boxes by hand, and other tools, such as monitoring, CMDB, telemetry, separately.  \n",
    "And if you have got some pager or service requests, you have to do all of them manually.\n",
    "\n",
    "In these days, we can set up all the boxes automatically (except for hardware tasks :( ), and update other tool settings simultaneously.\n",
    "- although you have to write down a lot of plugin if your environment uses a lot o os/mw/hw etc\n",
    "\n",
    "You can also define a lot of jobs to deal with pager and service requests to make most of them done automatically, and make all the task you have to do be to check and to review.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
